{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4638cce3",
   "metadata": {},
   "source": [
    "#### This is the Text Preprocessing Step of NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdd4e8",
   "metadata": {},
   "source": [
    "#### LowerCasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222f2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194666aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb22d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fdd5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3c1655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f6fa1",
   "metadata": {},
   "source": [
    "#### Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4195964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile(r'<.*?>')\n",
    "    return pattern.sub(\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90e8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3222dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e555432",
   "metadata": {},
   "source": [
    "#### Remove URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8cfbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "text2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "text3 = 'Google search here www.google.com'\n",
    "text4 = 'For notebook click https://www.kaggle.com/campusx/notebook8223fc1abb to search check www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7a17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a74410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out my notebook \n",
      "Check out my notebook \n",
      "Google search here \n",
      "For notebook click  to search check \n"
     ]
    }
   ],
   "source": [
    "print(remove_url(text1))\n",
    "print(remove_url(text2))\n",
    "print(remove_url(text3))\n",
    "print(remove_url(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bed00",
   "metadata": {},
   "source": [
    "#### Remove Pumctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb0ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a952030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4090af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452998f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b184d",
   "metadata": {},
   "source": [
    "##### Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04119d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_slang_dict = {\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"imho\": \"in my humble opinion\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"omfg\": \"oh my freaking god\",\n",
    "    \"nvm\": \"never mind\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"wya\": \"where you at\",\n",
    "    \"wtf\": \"what the f***\",\n",
    "    \"wth\": \"what the heck\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"bfn\": \"bye for now\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"g2g\": \"got to go\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ty\": \"thank you\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"yw\": \"you're welcome\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"pm\": \"private message\",\n",
    "    \"ama\": \"ask me anything\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"bruh\": \"brother / dude\",\n",
    "    \"sis\": \"sister / close friend\",\n",
    "    \"fam\": \"family / close friends\",\n",
    "    \"bae\": \"before anyone else\",\n",
    "    \"bb\": \"baby\",\n",
    "    \"bf\": \"boyfriend\",\n",
    "    \"gf\": \"girlfriend\",\n",
    "    \"bff\": \"best friends forever\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ilu\": \"I love you\",\n",
    "    \"ilysm\": \"I love you so much\",\n",
    "    \"xoxo\": \"hugs and kisses\",\n",
    "    \"stfu\": \"shut the f*** up\",\n",
    "    \"gtfo\": \"get the f*** out\",\n",
    "    \"fomo\": \"fear of missing out\",\n",
    "    \"bae\": \"before anyone else\",\n",
    "    \"lit\": \"exciting / amazing\",\n",
    "    \"savage\": \"bold / brutally honest\",\n",
    "    \"slay\": \"do something really well\",\n",
    "    \"noob\": \"newbie / beginner\",\n",
    "    \"pro\": \"professional\",\n",
    "    \"v\": \"very\",\n",
    "    \"rn\": \"right now\",\n",
    "    \"tbt\": \"throwback Thursday\",\n",
    "    \"wcw\": \"woman crush Wednesday\",\n",
    "    \"mcm\": \"man crush Monday\",\n",
    "    \"icymi\": \"in case you missed it\",\n",
    "    \"fr\": \"for real\",\n",
    "    \"sus\": \"suspicious\",\n",
    "    \"cap\": \"lie / false\",\n",
    "    \"no cap\": \"not lying / true\",\n",
    "    \"ok boomer\": \"dismissive response to older people\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"ofc\": \"of course\",\n",
    "    \"otp\": \"one true pairing\",\n",
    "    \"smol\": \"small (cute way)\",\n",
    "    \"uwu\": \"cute expression\",\n",
    "    \"owo\": \"surprised expression\",\n",
    "    \"bc\": \"because\",\n",
    "    \"bday\": \"birthday\",\n",
    "    \"hbd\": \"happy birthday\",\n",
    "    \"gm\": \"good morning\",\n",
    "    \"gn\": \"good night\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"msg\": \"message\",\n",
    "    \"pic\": \"picture\",\n",
    "    \"vid\": \"video\",\n",
    "    \"pls\": \"please\",\n",
    "    \"plz\": \"please\",\n",
    "    \"pov\": \"point of view\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"tmi\": \"too much information\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"atm\": \"at the moment\",\n",
    "    \"bday\": \"birthday\",\n",
    "    \"bffl\": \"best friends for life\",\n",
    "    \"dnd\": \"do not disturb\",\n",
    "    \"fml\": \"f*** my life\",\n",
    "    \"grats\": \"congratulations\",\n",
    "    \"hand\": \"have a nice day\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"mf\": \"motherf***er\",\n",
    "    \"ngl\": \"not gonna lie\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"roflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"sup\": \"what's up\",\n",
    "    \"ttfn\": \"ta-ta for now\",\n",
    "    \"wyd\": \"what you doing\",\n",
    "    \"wbu\": \"what about you\",\n",
    "    \"w/e\": \"whatever\",\n",
    "    \"wtv\": \"whatever\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a7c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.lower() in chat_slang_dict:   \n",
    "            new_text.append(chat_slang_dict[w.lower()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "844f6e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what about you how you'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('wbu how you')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2e3ef",
   "metadata": {},
   "source": [
    "#### Spelling Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92290c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7d0ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"ceertain thingss are imperfects in the countrey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc475804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain things are imperfect in the country'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "textblb = TextBlob(text)\n",
    "textblb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3de57",
   "metadata": {},
   "source": [
    "#### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e0c1a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\Karan\n",
      "[nltk_data]     Mehta\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4abeda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x= new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13006de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67f21e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef74171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lmao '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Lmao ðŸ˜‚ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c7b16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (2.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dc0e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is ðŸ”¥'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c452f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the movie. It was :face_blowing_a_kiss:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('Loved the movie. It was ðŸ˜˜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b53e27",
   "metadata": {},
   "source": [
    "#### Using Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63fe6a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa5b56dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31a841ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f8ebca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826db1d",
   "metadata": {},
   "source": [
    "#### 2. Using Regular Expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1fa12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4c2790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8016db5",
   "metadata": {},
   "source": [
    "#### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4afb69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b8dbef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to c:\\Users\\Karan\n",
      "[nltk_data]     Mehta\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ebc03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fd39c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ed27e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a172ba6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'nks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c721e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e05ff7",
   "metadata": {},
   "source": [
    "#### Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5cede60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karan mehta\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b434b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ae449a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a5d101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am going to delhi"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80f7230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "going\n",
      "to\n",
      "delhi\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d4e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
